{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# \ud83e\udde0 Master Data Preparation Notebook \u2014 Unified Cleaning, Normalization & Transformation\n", "This notebook integrates all datasets (Sales, Customer, Finance, Employee, Product, Supplier, RAG Docs, KPI) for preprocessing and model training preparation."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 1: Imports & Setup\n", "import pandas as pd\n", "import numpy as np\n", "import os\n", "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n", "from sklearn.impute import SimpleImputer\n", "from sklearn.model_selection import train_test_split\n", "import re, string\n", "\n", "# Define storage path\n", "BASE_PATH = 'processed_data'\n", "os.makedirs(BASE_PATH, exist_ok=True)\n", "print('Processed data will be stored in:', BASE_PATH)\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 2: Load all datasets\n", "sales = pd.read_csv('sales_data.csv', parse_dates=['order_date'])\n", "customers = pd.read_csv('customer_data.csv', parse_dates=['signup_date','last_purchase_date'])\n", "finance = pd.read_csv('finance_data.csv', parse_dates=['transaction_date'])\n", "employees = pd.read_csv('employee_data.csv', parse_dates=['joining_date'])\n", "products = pd.read_csv('product_data.csv', parse_dates=['launch_date'])\n", "suppliers = pd.read_csv('supplier_data.csv', parse_dates=['contract_start','contract_end'])\n", "documents = pd.read_csv('business_documents.csv', parse_dates=['created_date'])\n", "kpi = pd.read_csv('daily_kpi_data.csv', parse_dates=['date'])\n", "print('\u2705 All datasets loaded successfully.')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 3: Cleaning \u2014 Missing values & duplicates\n", "def clean_df(df):\n", "    df = df.drop_duplicates()\n", "    df = df.replace(['None','nan','NaN','NULL','null','?',''], np.nan)\n", "    imputer = SimpleImputer(strategy='most_frequent')\n", "    df[:] = imputer.fit_transform(df)\n", "    return df\n", "\n", "sales = clean_df(sales)\n", "customers = clean_df(customers)\n", "finance = clean_df(finance)\n", "employees = clean_df(employees)\n", "products = clean_df(products)\n", "suppliers = clean_df(suppliers)\n", "documents = clean_df(documents)\n", "kpi = clean_df(kpi)\n", "print('\u2705 Missing values handled and duplicates removed.')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 4: Data Normalization / Scaling (for numerical columns)\n", "scaler = MinMaxScaler()\n", "\n", "def scale_numerical(df):\n", "    num_cols = df.select_dtypes(include=['float64','int64']).columns\n", "    df[num_cols] = scaler.fit_transform(df[num_cols])\n", "    return df\n", "\n", "sales = scale_numerical(sales)\n", "customers = scale_numerical(customers)\n", "finance = scale_numerical(finance)\n", "employees = scale_numerical(employees)\n", "products = scale_numerical(products)\n", "suppliers = scale_numerical(suppliers)\n", "kpi = scale_numerical(kpi)\n", "print('\u2705 Numerical normalization completed.')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 5: Encoding categorical variables\n", "le = LabelEncoder()\n", "\n", "def encode_categorical(df):\n", "    cat_cols = df.select_dtypes(include=['object']).columns\n", "    for col in cat_cols:\n", "        try:\n", "            df[col] = le.fit_transform(df[col].astype(str))\n", "        except:\n", "            pass\n", "    return df\n", "\n", "sales = encode_categorical(sales)\n", "customers = encode_categorical(customers)\n", "finance = encode_categorical(finance)\n", "employees = encode_categorical(employees)\n", "products = encode_categorical(products)\n", "suppliers = encode_categorical(suppliers)\n", "documents = encode_categorical(documents)\n", "kpi = encode_categorical(kpi)\n", "print('\u2705 Categorical encoding completed.')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 6: Feature engineering examples (date parts)\n", "def add_date_features(df, date_col):\n", "    if date_col in df.columns:\n", "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n", "        df[date_col + '_year'] = df[date_col].dt.year\n", "        df[date_col + '_month'] = df[date_col].dt.month\n", "        df[date_col + '_day'] = df[date_col].dt.day\n", "        df[date_col + '_weekday'] = df[date_col].dt.weekday\n", "    return df\n", "\n", "sales = add_date_features(sales, 'order_date')\n", "finance = add_date_features(finance, 'transaction_date')\n", "employees = add_date_features(employees, 'joining_date')\n", "products = add_date_features(products, 'launch_date')\n", "suppliers = add_date_features(suppliers, 'contract_end')\n", "kpi = add_date_features(kpi, 'date')\n", "print('\u2705 Date-based features created.')\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 7: Merge examples (to build a master dataset for ML)\n", "master = sales.merge(customers, on='customer_id', how='left')\\\n", "               .merge(products, on='product_id', how='left', suffixes=('_sale','_prod'))\\\n", "               .merge(finance, left_on='region_sale', right_on='department', how='left')\n", "\n", "print('Merged master dataset shape:', master.shape)\n", "master.head()\n"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# STEP 8: Save processed datasets\n", "sales.to_csv(f'{BASE_PATH}/sales_cleaned.csv', index=False)\n", "customers.to_csv(f'{BASE_PATH}/customer_cleaned.csv', index=False)\n", "finance.to_csv(f'{BASE_PATH}/finance_cleaned.csv', index=False)\n", "employees.to_csv(f'{BASE_PATH}/employee_cleaned.csv', index=False)\n", "products.to_csv(f'{BASE_PATH}/product_cleaned.csv', index=False)\n", "suppliers.to_csv(f'{BASE_PATH}/supplier_cleaned.csv', index=False)\n", "documents.to_csv(f'{BASE_PATH}/documents_cleaned.csv', index=False)\n", "kpi.to_csv(f'{BASE_PATH}/kpi_cleaned.csv', index=False)\n", "master.to_csv(f'{BASE_PATH}/master_dataset.csv', index=False)\n", "print('\u2705 All cleaned datasets saved in:', BASE_PATH)\n"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \ud83d\ude80 Ready for Model Training\n", "- The processed data in `/processed_data/` can now be used for supervised learning (classification/regression) or unsupervised modeling (clustering, segmentation).\n", "- Extend feature generation for domain-specific model inputs (e.g., KPI lag features, text embeddings, etc.).\n"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python"}}, "nbformat": 4, "nbformat_minor": 0}